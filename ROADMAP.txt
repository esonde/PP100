# Parlamento Live — Piano di Implementazione (GitHub‑only)

> Obiettivo: rilasciare **piccoli incrementi funzionali** (vertical slice) che mantengano il repo sempre in stato deployabile su GitHub Pages + Actions, senza backend. Ogni milestone produce **file pubblici stabili** (data contract) che il web legge direttamente.

---

## Principi guida

* **Walking skeleton**: prima un sito statico che legge **file finti ma con schema definitivo**, poi sostituiamo le sorgenti con pipeline reali.
* **Data contracts**: ogni step scrive file con **schema versionato** in `schemas/` e validato in CI. Cambiare uno schema richiede bump `*_version` e migrazione.
* **Idempotenza e cache**: ogni job ricalcola solo il necessario; uso di chiavi deterministiche (sha256) e cache per embeddings/LLM.
* **Feature flags**: pubblicazione gated da `manifest.json` (attiva/disattiva feed e cards per pipeline incomplete).
* **Fail-soft**: se cade una pipeline, il job continua e pubblica ciò che è sano (status nel manifest).
* **Zero lock‑in**: modelli e vettori in LFS/Release asset; librerie pin‑version e opzioni open-source by default.

---

## Roadmap per milestone (M0 → M8)

### M0 — Walking Skeleton (sito + contratti dati)

**Scopo**: vedere una pagina pubblica che legge `public/data/*.jsonl|parquet` fittizi.

**Deliverable**

* `web/` (Next.js static export o SvelteKit adapter-static) con:

  * Home + `/feed` che legge `cards-YYYYMMDD.jsonl`.
  * `/metrics` che legge `scores-rolling.parquet` (mock) e mostra PP.
* `public/data/manifest.json` (schema definitivo) + mock dei principali file.
* `schemas/` con JSON Schema/pydantic per: `interventions`, `features`, `cards`, `llm-events`, `scores-rolling`, `manifest`.
* CI base: Pages deploy, lint & schema-validate file mock.
* `Makefile`, `pre-commit`, `.env.example`, `CONTRIBUTING.md` (stile commit/PR/labels).

**Accettazione**

* Build e deploy passano; il sito mostra 3 card mock e una tabella PP.

**Rischi/mitigazioni**: nessuno lato sorgenti reali; attenzione a dimensione asset/Pages.

---

### M1 — P0 Ingest minimo (live HTML only)

**Scopo**: estrarre **interventi normalizzati** (solo live HTML) da Camera + Senato.

**Deliverable**

* `ingest/run_ingest.py`: adapter `camera_html.py`, `senato_html.py` con **ETag/If-Modified-Since** e backoff.
* Normalizzazione → `interventions-YYYYMMDD.parquet` con: `id, camera_senato, seduta, ts_start, oratore, gruppo, text, spans_frasi[], source_url`.
* Test unitari per parsing (snapshot di 2 pagine reali in `ingest/tests/fixtures/`).
* Log strutturati (JSON) + conteggio nuovi interventi.

**Accettazione**

* A cron manuale, produce un Parquet con ≥20 interventi reali in giornata e `manifest.json` punta al file.

**Rischi**

* HTML volatile → **Mitigazione**: estrattori via selettori robusti + fallback a regex e normalizzazioni; mantenere fixtures.

---

### M2 — P1 Stile & P2 Topics "light"
Scopo: arricchire con feature a basso costo e stabili; inizializzare **person_features**.
Deliverable
• enrich/run_enrich.py con moduli:
  – style.py (Gulpease, len, %hedges, %citazioni)
  – topic_light.py (tf-idf + NMF 8 topic; fit settimanale)
Output:
  – features-YYYYMMDD.parquet (topic_vec[8], top_terms)
  – person_features.parquet (prime metriche per-persona: talk_time_share, pathos_pct, policy_density rolling 30d; field method_version)
  – grafici PNG in public/plots/
UI: /metrics aggiornato.
Rischi: CPU su Actions → cache modelli/vectorizer.

### M3 — fastText triage (Argomentatività + Check-worthiness)
Scopo: ridurre il costo LLM selezionando frasi candidate; loggare effetti nel **person_features**.
Deliverable
• fasttext/train_arg.py, train_cw.py, infer.py (+ gold set).
Output:
  – arg-score-YYYYMMDD.parquet, claims-cw-ranked-YYYYMMDD.jsonl
  – aggiornamento person_features (arg_rate_rolling, cw_hit_rate)
Accettazione: badge "triage attivo" visibile; coerenza rolling.

### M4 — Near-duplicate & Agenda Adoption
Scopo: cluster simili per misurare diffusione narrative; prime **badge** deterministiche.
Deliverable
• Prefiltro cosine (fastText) + conferma E5-small; cache embeddings.
Output:
  – duplicates-YYYYMMDD.parquet (cluster_id, leader_id, lag, size)
  – badges.jsonl (Copia-incolla Radar p95 con ruleset_version)
UI: badge in /feed.
Rischi: costi embeddings → cache su disco.

### M5 — LLM ragionatore (JSON-only) + Validator
Scopo: estrazioni affidabili su subset con un solo LLM; popolamento **claims/commitments** e riflessi nel profilo.
Deliverable
• enrich/llm_runner.py (prompt Appendix A1, cache sha, validator, gating ≥0.66).
Output:
  – llm-events-YYYYMMDD.jsonl + cards-YYYYMMDD.jsonl
  – person_features aggiornato (ad_hominem_rate, claim_density, commitment_count)
  – provenance & audit (generated_by_commit, evidence_refs)
UI: /feed con link+highlight; fallacia del minuto.
Rischi: allucinazioni → span-proof + whitelist + gating.

### M6 — Stance & Join voti/atti + Indicatori & PP
Scopo: chiudere il cerchio discorso→voto→PP; **Profile Pack** iniziale.
Deliverable
• models/stance.joblib (3 classi), join votazioni → join-votes-YYYYMMDD.parquet.
• scoring/run_scoring.py per Q/K/V/I/R, PP rolling 30–60 gg → scores-rolling.parquet.
• profiles/build_profile_pack.py: genera public/data/profiles/{person_id}.json (snapshot con PP, componenti, segnali chiave, badges).
UI: /politico/[slug] legge Profile Pack (fetch singola); breakdown PP + CI.
Accettazione: PP per ≥10 oratori con CI (bootstrap) e pagine profilo on.
Rischi: mapping rumoroso → flag low-confidence + filtri temporali/keywords.

### M7 — Framework Agentico (Insight & Blog)
Scopo: report automatici giornalieri + registro previsioni; integrazione profili.
Deliverable
• insights/run_insights.py (Profiler→Ideatore→Tester→Curatore→Redattore→Archivista).
• Output: /web/content/blog/YYYY-MM-DD.md(x), public/rss.xml, predictions.jsonl.
• Integrazione links da Profile Pack a insight (cross-ref persona↔card↔blog).
UI: indice blog + pagina "Trasparenza" con errori ex-post.
Rischi: multiple testing → Benjamini–Hochberg + holdout temporale.

### M8 — Nightly refine (XML/stenografici) & Qualità
Scopo: rielaborare con sorgenti "gold"; aggiornare **registry SCD2** prima dei ricalcoli; qualità/trasparenza.
Deliverable
• Pipeline: registry SCD2 → parse XML → riallinea span → ricalcolo llm-events/PP.
• Audit completo: public/data/audit/*.jsonl (pp_version, ruleset_version, motivazioni).
• Gold set esteso (κ≥0.65) e backtest 12 mesi; pagina "Come misuriamo" aggiornata.
Accettazione
• Differenze live vs refine mostrate/versionate; riproducibilità garantita.

### Checklists aggiuntive
• Registry
  [ ] Schemi persons/party/roles/memberships
  [ ] Script build_registry.py / build_memberships.py
  [ ] Fixture + test alias/omografi
• Profile Pack
  [ ] build_profile_pack.py
  [ ] schemas/profile_pack.schema.json
  [ ] UI /politico/[slug] → fetch singola
• Feature Store
  [ ] person_features.parquet con method_version & CI
  [ ] badges.jsonl con ruleset_version
• Audit & Provenance
  [ ] evidence_refs ovunque richiesto
  [ ] generated_by_commit nei file pubblicabili
  [ ] public/data/audit/*.jsonl e pagina trasparenza

---

## Struttura repo (definitiva, incrementale)

```
.
├─ ingest/                 # P0
│  ├─ adapters/{camera_html,senato_html,xml_*,pdf_*}.py
│  ├─ run_ingest.py
│  └─ tests/
├─ enrich/                 # P1–P8
│  ├─ style.py  topic_light.py  duplicates.py
│  ├─ fasttext/{train_*.py,infer.py,models/}
│  ├─ llm_runner.py  validators.py  cards.py
│  ├─ models/{stance.joblib,topic_nmf.joblib}
│  ├─ run_enrich.py
│  └─ tests/
├─ scoring/                # P9–P11
│  ├─ run_scoring.py
│  └─ tests/
├─ insights/               # Orchestratore agentico
│  ├─ run_insights.py  prompts/
│  └─ tests/
├─ web/                    # Next.js/SvelteKit static
│  ├─ src/  package.json
│  └─ scripts/read_data.ts
├─ public/data/            # JSON/Parquet pubblicati
├─ public/plots/           # grafici png
├─ identities/             # sync registry & SCD2 (persons/parties/roles)
│  ├─ build_registry.py    # aggiorna persons/person_xref/aliases/party_*
│  └─ build_memberships.py # aggiorna party_membership/roles
├─ profiles/               # materializzazione viste profilo
│  └─ build_profile_pack.py
├─ schemas/                # JSON Schema/pydantic models
├─ .github/workflows/
│  ├─ ingest.yml           # */5 — pipeline + build + deploy
│  ├─ nightly.yml          # 02:00 — registry SCD2 + refine XML + ricalcoli
│  └─ insights.yml         # 02:30 — report/RSS
├─ Makefile  pre-commit-config.yaml
├─ README.md  CONTRIBUTING.md  CODE_OF_CONDUCT.md
└─ .env.example
```

## GitHub Actions — progressivo (concurrency & resilienza)

* **concurrency**: `group: pipeline-${{ github.ref }}` con `cancel-in-progress: true`.
* **jobs**: `setup → ingest → enrich → scoring → build_web → deploy_pages`.
* **cache**: pip + embeddings (`actions/cache`), artefatti Parquet per 1 giorno.
* **telemetria**: summary Markdown del job con conteggi record; sezione "Degradazioni disattivate".

## Data contracts & validazione

* `schemas/*.json` + `scripts/validate_schemas.py` in CI.
* Ogni file in `public/data/` ha `version` e `generated_at` (UTC) + checksum nel `manifest`.

## Rischi chiave e piani B

1. **Cambio HTML sorgenti** → abstract adapter + fixtures + fallback `requests_html` + XPaths multipli.
2. **PDF complessi (Senato)** → estrazione `pdfminer.six` + heuristics; se fragile, rimandare a M8 (XML night).
3. **Limiti cron Pages/Actions** → consolidare in un job unico e ridurre heavy steps a 15' se necessario.
4. **Costi LLM** → gating aggressivo (M3) e `prompt caching`; limite max call per job.
5. **Dimensione repo** → ruotare file per data, tenere solo ultimi N giorni in `main`, archivio su Releases.

## Qualità & misurazione (Definition of Done)

* **Schema lock**: nessun breaking change senza bump.
* **Test**: 80% per parsing/validatori; golden tests su 10 esempi reali per pipeline critiche.
* **Calibrazione**: κ di Cohen ≥ 0.65 sui gold set (fallacie/stance) prima di pubblicare metriche globali.
* **Trasparenza**: pagina "Come misuriamo" con formule PP e pesi versionati.

## Checklist iniziale (aprire come Issues con label)

* [ ] M0: scaffold web + mock data + manifest + CI Pages
* [ ] M0: schemas + validazione CI + Makefile + pre‑commit
* [ ] M1: adapter Camera (HTML) + tests
* [ ] M1: adapter Senato (HTML) + tests
* [ ] M1: normalizzazione Parquet + spans frasi
* [ ] M1.5: registry persons/parties + schemi + test fixture
* [ ] M2: style.py + topic_light.py + modelli NMF con cache + person_features
* [ ] M3: fastText train/infer (arg, cw) + gold set + person_features update
* [ ] M4: duplicates (fastText avg → E5‑small) + cache embeddings + badges
* [ ] M5: llm_runner + validators + cards feed + provenance
* [ ] M6: stance tf‑idf + join voti + scoring PP + Profile Pack
* [ ] M7: orchestratore insight + blog + RSS + cross-ref profili
* [ ] M8: refine XML/stenografico + audit qualità + registry SCD2

## Script pronti‑all'uso (snippet CLI)

```bash
# Validazione schemi prima del commit
make validate

# Esecuzione locale end‑to‑end su sample
make run-all   # ingest → enrich → scoring → web build

# Rigenera feed con gating e cards
python enrich/llm_runner.py --day 2025-08-24 --limit 300 --min-conf 0.66
python scoring/run_scoring.py --window 60
```

## Note sull'UI

* `/feed`: cards ordinarie con badge (evidence, confidenza, severità, cluster size).
* `/politico/[slug]`: pagina oratore con PP rolling + breakdown Q/K/V/I/R.
* `/metodo`: spiegazione misure, formule, versionamento pesi PP.
* `/blog`: report giornaliero + indice + RSS.

---

### Prossimi passi consigliati

1. **Esegui M0** e committa mock + schemas + CI Pages.
2. **Apri tutte le Issues della checklist** (epic per milestone) e assegna priorità.
3. **Procedi M1→M1.5** per avere il primo dato reale a UI stabile + registry base.
4. **Blocca i contratti** prima di attivare LLM (M5).

> Con questa sequenza hai sempre un sito funzionante; ogni milestone aggiunge valore visibile mentre limita l'esposizione al rischio.
